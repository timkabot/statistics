{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STDS HW10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timkabot/statistics/blob/main/BernoulliBandit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyK9P8hgQilC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "a7fa607a-b1c9-4f22-9d8b-81e809be5077"
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from scipy.stats import beta\n",
        "import matplotlib  # noqa\n",
        "matplotlib.use('Agg')  # noqa\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "class Bandit(object):\n",
        "\n",
        "    def generate_reward(self, i):\n",
        "        raise NotImplementedError\n",
        "class BernoulliBandit(Bandit):\n",
        "\n",
        "    def __init__(self, n, probas=None):\n",
        "        assert probas is None or len(probas) == n\n",
        "        self.n = n\n",
        "        if probas is None:\n",
        "            np.random.seed(int(time.time()))\n",
        "            self.probas = [np.random.random() for _ in range(self.n)]\n",
        "        else:\n",
        "            self.probas = probas\n",
        "\n",
        "        self.best_proba = max(self.probas)\n",
        "\n",
        "    def generate_reward(self, i):\n",
        "        # The player selected the i-th machine.\n",
        "        if np.random.random() < self.probas[i]:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "class Solver(object):\n",
        "    def __init__(self, bandit):\n",
        "        \"\"\"\n",
        "        bandit (Bandit): the target bandit to solve.\n",
        "        \"\"\"\n",
        "        assert isinstance(bandit, BernoulliBandit)\n",
        "        np.random.seed(int(time.time()))\n",
        "\n",
        "        self.bandit = bandit\n",
        "\n",
        "        self.counts = [0] * self.bandit.n\n",
        "        self.actions = []  # A list of machine ids, 0 to bandit.n-1.\n",
        "        self.regret = 0.  # Cumulative regret.\n",
        "        self.regrets = [0.]  # History of cumulative regret.\n",
        "\n",
        "    def update_regret(self, i):\n",
        "        # i (int): index of the selected machine.\n",
        "        self.regret += self.bandit.best_proba - self.bandit.probas[i]\n",
        "        self.regrets.append(self.regret)\n",
        "\n",
        "    @property\n",
        "    def estimated_probas(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def run_one_step(self):\n",
        "        \"\"\"Return the machine index to take action on.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def run(self, num_steps):\n",
        "        assert self.bandit is not None\n",
        "        for _ in range(num_steps):\n",
        "            i = self.run_one_step()\n",
        "\n",
        "            self.counts[i] += 1\n",
        "            self.actions.append(i)\n",
        "            self.update_regret(i)\n",
        "\n",
        "\n",
        "class EpsilonGreedy(Solver):\n",
        "    def __init__(self, bandit, eps, init_proba=1.0):\n",
        "        \"\"\"\n",
        "        eps (float): the probability to explore at each time step.\n",
        "        init_proba (float): default to be 1.0; optimistic initialization\n",
        "        \"\"\"\n",
        "        super(EpsilonGreedy, self).__init__(bandit)\n",
        "\n",
        "        assert 0. <= eps <= 1.0\n",
        "        self.eps = eps\n",
        "\n",
        "        self.estimates = [init_proba] * self.bandit.n  # Optimistic initialization\n",
        "\n",
        "    @property\n",
        "    def estimated_probas(self):\n",
        "        return self.estimates\n",
        "\n",
        "    def run_one_step(self):\n",
        "        if np.random.random() < self.eps:\n",
        "            # Let's do random exploration!\n",
        "            i = np.random.randint(0, self.bandit.n)\n",
        "        else:\n",
        "            # Pick the best one.\n",
        "            i = max(range(self.bandit.n), key=lambda x: self.estimates[x])\n",
        "\n",
        "        r = self.bandit.generate_reward(i)\n",
        "        self.estimates[i] += 1. / (self.counts[i] + 1) * (r - self.estimates[i])\n",
        "\n",
        "        return i\n",
        "\n",
        "\n",
        "class UCB1(Solver):\n",
        "    def __init__(self, bandit, init_proba=1.0):\n",
        "        super(UCB1, self).__init__(bandit)\n",
        "        self.t = 0\n",
        "        self.estimates = [init_proba] * self.bandit.n\n",
        "\n",
        "    @property\n",
        "    def estimated_probas(self):\n",
        "        return self.estimates\n",
        "\n",
        "    def run_one_step(self):\n",
        "        self.t += 1\n",
        "\n",
        "        # Pick the best one with consideration of upper confidence bounds.\n",
        "        i = max(range(self.bandit.n), key=lambda x: self.estimates[x] + np.sqrt(\n",
        "            2 * np.log(self.t) / (1 + self.counts[x])))\n",
        "        r = self.bandit.generate_reward(i)\n",
        "\n",
        "        self.estimates[i] += 1. / (self.counts[i] + 1) * (r - self.estimates[i])\n",
        "\n",
        "        return i\n",
        "\n",
        "\n",
        "class BayesianUCB(Solver):\n",
        "    \"\"\"Assuming Beta prior.\"\"\"\n",
        "\n",
        "    def __init__(self, bandit, c=3, init_a=1, init_b=1):\n",
        "        \"\"\"\n",
        "        c (float): how many standard dev to consider as upper confidence bound.\n",
        "        init_a (int): initial value of a in Beta(a, b).\n",
        "        init_b (int): initial value of b in Beta(a, b).\n",
        "        \"\"\"\n",
        "        super(BayesianUCB, self).__init__(bandit)\n",
        "        self.c = c\n",
        "        self._as = [init_a] * self.bandit.n\n",
        "        self._bs = [init_b] * self.bandit.n\n",
        "\n",
        "    @property\n",
        "    def estimated_probas(self):\n",
        "        return [self._as[i] / float(self._as[i] + self._bs[i]) for i in range(self.bandit.n)]\n",
        "\n",
        "    def run_one_step(self):\n",
        "        # Pick the best one with consideration of upper confidence bounds.\n",
        "        i = max(\n",
        "            range(self.bandit.n),\n",
        "            key=lambda x: self._as[x] / float(self._as[x] + self._bs[x]) + beta.std(\n",
        "                self._as[x], self._bs[x]) * self.c\n",
        "        )\n",
        "        r = self.bandit.generate_reward(i)\n",
        "\n",
        "        # Update Gaussian posterior\n",
        "        self._as[i] += r\n",
        "        self._bs[i] += (1 - r)\n",
        "\n",
        "        return i\n",
        "\n",
        "\n",
        "class ThompsonSampling(Solver):\n",
        "    def __init__(self, bandit, init_a=1, init_b=1):\n",
        "        \"\"\"\n",
        "        init_a (int): initial value of a in Beta(a, b).\n",
        "        init_b (int): initial value of b in Beta(a, b).\n",
        "        \"\"\"\n",
        "        super(ThompsonSampling, self).__init__(bandit)\n",
        "\n",
        "        self._as = [init_a] * self.bandit.n\n",
        "        self._bs = [init_b] * self.bandit.n\n",
        "\n",
        "    @property\n",
        "    def estimated_probas(self):\n",
        "        return [self._as[i] / (self._as[i] + self._bs[i]) for i in range(self.bandit.n)]\n",
        "\n",
        "    def run_one_step(self):\n",
        "        samples = [np.random.beta(self._as[x], self._bs[x]) for x in range(self.bandit.n)]\n",
        "        i = max(range(self.bandit.n), key=lambda x: samples[x])\n",
        "        r = self.bandit.generate_reward(i)\n",
        "\n",
        "        self._as[i] += r\n",
        "        self._bs[i] += (1 - r)\n",
        "\n",
        "        return i\n",
        "def plot_results(solvers, solver_names, figname):\n",
        "    \"\"\"\n",
        "    Plot the results by multi-armed bandit solvers.\n",
        "    Args:\n",
        "        solvers (list<Solver>): All of them should have been fitted.\n",
        "        solver_names (list<str)\n",
        "        figname (str)\n",
        "    \"\"\"\n",
        "    assert len(solvers) == len(solver_names)\n",
        "    assert all(map(lambda s: isinstance(s, Solver), solvers))\n",
        "    assert all(map(lambda s: len(s.regrets) > 0, solvers))\n",
        "\n",
        "    b = solvers[0].bandit\n",
        "\n",
        "    fig = plt.figure(figsize=(14, 4))\n",
        "    fig.subplots_adjust(bottom=0.3, wspace=0.3)\n",
        "\n",
        "    ax1 = fig.add_subplot(131)\n",
        "    ax2 = fig.add_subplot(132)\n",
        "    ax3 = fig.add_subplot(133)\n",
        "\n",
        "    # Sub.fig. 1: Regrets in time.\n",
        "    for i, s in enumerate(solvers):\n",
        "        ax1.plot(range(len(s.regrets)), s.regrets, label=solver_names[i])\n",
        "\n",
        "    ax1.set_xlabel('Time step')\n",
        "    ax1.set_ylabel('Cumulative regret')\n",
        "    ax1.legend(loc=9, bbox_to_anchor=(1.82, -0.25), ncol=5)\n",
        "    ax1.grid('k', ls='--', alpha=0.3)\n",
        "\n",
        "    # Sub.fig. 2: Probabilities estimated by solvers.\n",
        "    sorted_indices = sorted(range(b.n), key=lambda x: b.probas[x])\n",
        "    ax2.plot(range(b.n), [b.probas[x] for x in sorted_indices], 'k--', markersize=12)\n",
        "    for s in solvers:\n",
        "        ax2.plot(range(b.n), [s.estimated_probas[x] for x in sorted_indices], 'x', markeredgewidth=2)\n",
        "    ax2.set_xlabel('Actions sorted by ' + r'$\\theta$')\n",
        "    ax2.set_ylabel('Estimated')\n",
        "    ax2.grid('k', ls='--', alpha=0.3)\n",
        "\n",
        "    # Sub.fig. 3: Action counts\n",
        "    for s in solvers:\n",
        "        ax3.plot(range(b.n), np.array(s.counts) / float(len(solvers[0].regrets)), ls='steps', lw=2)\n",
        "    ax3.set_xlabel('Actions')\n",
        "    ax3.set_ylabel('Frac. # trials')\n",
        "    ax3.grid('k', ls='--', alpha=0.3)\n",
        "\n",
        "    plt.savefig(figname)\n",
        "\n",
        "\n",
        "def experiment(K, N):\n",
        "    \"\"\"\n",
        "    Run a small experiment on solving a Bernoulli bandit with K slot machines,\n",
        "    each with a randomly initialized reward probability.\n",
        "    Args:\n",
        "        K (int): number of slot machiens.\n",
        "        N (int): number of time steps to try.\n",
        "    \"\"\"\n",
        "\n",
        "    b = BernoulliBandit(K)\n",
        "    print (\"Randomly generated Bernoulli bandit has reward probabilities:\\n\", b.probas)\n",
        "    print (\"The best machine has index: {} and proba: {}\".format(\n",
        "        max(range(K), key=lambda i: b.probas[i]), max(b.probas)))\n",
        "\n",
        "    test_solvers = [\n",
        "        # EpsilonGreedy(b, 0),\n",
        "        # EpsilonGreedy(b, 1),\n",
        "        EpsilonGreedy(b, 0.01),\n",
        "        UCB1(b),\n",
        "        BayesianUCB(b, 3, 1, 1),\n",
        "        ThompsonSampling(b, 1, 1)\n",
        "    ]\n",
        "    names = [\n",
        "        # 'Full-exploitation',\n",
        "        # 'Full-exploration',\n",
        "        r'$\\epsilon$' + '-Greedy',\n",
        "        'UCB1',\n",
        "        'Bayesian UCB',\n",
        "        'Thompson Sampling'\n",
        "    ]\n",
        "\n",
        "    for s in test_solvers:\n",
        "        s.run(N)\n",
        "\n",
        "    plot_results(test_solvers, names, \"results_K{}_N{}.png\".format(K, N))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    experiment(10, 5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomly generated Bernoulli bandit has reward probabilities:\n",
            " [0.8531600523912732, 0.3823447368025016, 0.47266865796336754, 0.13470229307208104, 0.8315256463377911, 0.5787075873561822, 0.9918454801428144, 0.7747527826192129, 0.3396692173830108, 0.8949817157315788]\n",
            "The best machine has index: 6 and proba: 0.9918454801428144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:226: MatplotlibDeprecationWarning: Passing the drawstyle with the linestyle as a single string is deprecated since Matplotlib 3.1 and support will be removed in 3.3; please pass the drawstyle separately using the drawstyle keyword argument to Line2D or set_drawstyle() method (or ds/set_ds()).\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}